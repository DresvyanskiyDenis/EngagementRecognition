{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6d3198-7107-4559-af41-6973aef15652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "285447f7-aa7e-4961-9dd4-01c257f374e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params and paths\n",
    "path_to_train_frames=r'D:\\Databases\\DAiSEE\\DAiSEE\\train_preprocessed\\extracted_faces'\n",
    "path_to_train_labels=r'D:\\Databases\\DAiSEE\\DAiSEE\\Labels\\TrainLabels.csv'\n",
    "path_to_dev_frames=r'D:\\Databases\\DAiSEE\\DAiSEE\\dev_preprocessed\\extracted_faces'\n",
    "path_to_dev_labels=r'D:\\Databases\\DAiSEE\\DAiSEE\\Labels\\ValidationLabels.csv'\n",
    "path_to_test_frames=r'D:\\Databases\\DAiSEE\\DAiSEE\\test_preprocessed\\extracted_faces'\n",
    "path_to_test_labels=r'D:\\Databases\\DAiSEE\\DAiSEE\\Labels\\TestLabels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab97df36-95a6-4f44-a6c2-74ebc76f0b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load labels in dataframe\n",
    "train_labels=pd.read_csv(path_to_train_labels)\n",
    "dev_labels=pd.read_csv(path_to_dev_labels)\n",
    "test_labels=pd.read_csv(path_to_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd515f4-142a-4993-b43e-dd9e81380e0d",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Class distribution analysis**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "529fe60e-d760-45db-acd1-e0ad6ecd0088",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_distribution = train_labels.drop(columns=['ClipID'])['Engagement'].value_counts()\n",
    "train_distribution = train_distribution.reset_index()\n",
    "train_distribution.columns= ['num_class', 'train_engagement']\n",
    "dev_distribution = dev_labels.drop(columns=['ClipID'])['Engagement'].value_counts()\n",
    "dev_distribution = dev_distribution.reset_index()\n",
    "dev_distribution.columns= ['num_class', 'dev_engagement']\n",
    "test_distribution = test_labels.drop(columns=['ClipID'])['Engagement'].value_counts()\n",
    "test_distribution = test_distribution.reset_index()\n",
    "test_distribution.columns= ['num_class', 'test_engagement']\n",
    "all_distributions=train_distribution.merge(dev_distribution, on='num_class').merge(test_distribution, on='num_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dda9fa9-44cc-4f52-a7ce-d8993edf9b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='num_class'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_distributions.plot.bar(x='num_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21af3bab-5b97-4541-8975-4cf96cecccb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_class</th>\n",
       "      <th>train_engagement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>48.842852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>46.547219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3.975364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.634565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_class  train_engagement\n",
       "0          2         48.842852\n",
       "1          3         46.547219\n",
       "2          1          3.975364\n",
       "3          0          0.634565"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_distribution['train_engagement']=train_distribution['train_engagement']/train_distribution['train_engagement'].sum()*100\n",
    "train_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ad9b323-d156-432d-98e2-d943eb8598f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_class</th>\n",
       "      <th>dev_engagement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>56.892932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>31.490553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10.006998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.609517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_class  dev_engagement\n",
       "0          2       56.892932\n",
       "1          3       31.490553\n",
       "2          1       10.006998\n",
       "3          0        1.609517"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_distribution['dev_engagement']=dev_distribution['dev_engagement']/dev_distribution['dev_engagement'].sum()*100\n",
    "dev_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f39f72ee-b5ce-4957-8d8d-47c2c1676d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_class</th>\n",
       "      <th>test_engagement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>49.439462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>45.627803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4.708520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.224215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_class  test_engagement\n",
       "0          2        49.439462\n",
       "1          3        45.627803\n",
       "2          1         4.708520\n",
       "3          0         0.224215"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_distribution['test_engagement']=test_distribution['test_engagement']/test_distribution['test_engagement'].sum()*100\n",
    "test_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b450975-65d8-4b4a-b25e-b28e2ef7744b",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Confusion matrix for model**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aab56564-6cc7-4a9e-8e06-5ab5bee1c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, Callable, Union\n",
    "import sys\n",
    "import gc\n",
    "sys.path.append(r\"C:\\Users\\Denis\\PycharmProjects\\datatools\")\n",
    "from tensorflow_utils.models.CNN_models import get_EMO_VGGFace2, _get_pretrained_VGGFace2_model\n",
    "from tensorflow_utils.Layers import Non_local_block_multi_head\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "# model creation\n",
    "def get_model_with_local_att(dense_neurons_after_conv: Tuple[int,...],\n",
    "                                       dropout: float = 0.3,\n",
    "                                       regularization:Optional[tf.keras.regularizers.Regularizer]=None,\n",
    "                                       output_neurons: Union[Tuple[int,...], int] = 7, pooling_at_the_end: Optional[str] = None,\n",
    "                                       pretrained: bool = True,\n",
    "                                       path_to_weights: Optional[str] = None,\n",
    "                                       multi_head_attention:bool=True) -> tf.keras.Model:\n",
    "    pretrained_VGGFace2 = _get_pretrained_VGGFace2_model(path_to_weights, pretrained=pretrained)\n",
    "    x=pretrained_VGGFace2.get_layer('activation_48').output\n",
    "    if multi_head_attention:\n",
    "        x = Non_local_block_multi_head(num_heads=4,  output_channels=1024,\n",
    "                 head_output_channels=None,\n",
    "                 downsize_factor=8,\n",
    "                 shortcut_connection=True)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "    # take pooling or not\n",
    "    if pooling_at_the_end is not None:\n",
    "        if pooling_at_the_end=='avg':\n",
    "            x=tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        elif pooling_at_the_end=='max':\n",
    "            x=tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "        else:\n",
    "            raise AttributeError('Parameter pooling_at_the_end can be either \\'avg\\' or \\'max\\'. Got %s.'%(pooling_at_the_end))\n",
    "    # create Dense layers\n",
    "    for dense_layer_idx in range(len(dense_neurons_after_conv)-1):\n",
    "        num_neurons_on_layer=dense_neurons_after_conv[dense_layer_idx]\n",
    "        x = tf.keras.layers.Dense(num_neurons_on_layer, activation='relu', kernel_regularizer=regularization)(x)\n",
    "        if dropout:\n",
    "            x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    # pre-last Dense layer\n",
    "    num_neurons_on_layer=dense_neurons_after_conv[-1]\n",
    "    x = tf.keras.layers.Dense(num_neurons_on_layer, activation='relu')(x)\n",
    "    # If outputs should be several, then create several layers, otherwise one\n",
    "    if isinstance(output_neurons, tuple):\n",
    "        output_layers=[]\n",
    "        for num_output_neurons in output_neurons:\n",
    "            if dropout:\n",
    "                output_layer_i = tf.keras.layers.Dropout(dropout)(x)\n",
    "            output_layer_i = tf.keras.layers.Dense(128, activation='relu')(output_layer_i)\n",
    "            output_layer_i=tf.keras.layers.Dense(num_output_neurons, activation='softmax')(output_layer_i)\n",
    "            #output_layer_i=tf.keras.layers.Reshape((-1, 1))(output_layer_i)\n",
    "            output_layers.append(output_layer_i)\n",
    "    else:\n",
    "        output_layers = tf.keras.layers.Dense(output_neurons, activation='softmax')(x)\n",
    "        # in tf.keras.Model it should be always a list (even when it has only 1 element)\n",
    "        output_layers = [output_layers]\n",
    "    # create model\n",
    "    model=tf.keras.Model(inputs=pretrained_VGGFace2.inputs, outputs=output_layers)\n",
    "    del pretrained_VGGFace2\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model=get_model_with_local_att(dense_neurons_after_conv=(1024,),\n",
    "                                               dropout=0.5,\n",
    "                                               regularization=tf.keras.regularizers.l2(0.0001),\n",
    "                                               output_neurons=(4,), pooling_at_the_end='avg',\n",
    "                                               pretrained=True,\n",
    "                                               path_to_weights=r'C:\\Users\\Denis\\PycharmProjects\\vggface2_Keras\\vggface2_Keras\\model\\resnet50_softmax_dim512\\weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0be0af14-0a3e-4a50-a9bb-c941a071868d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "base_input (InputLayer)         [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2 (Conv2D)           (None, 112, 112, 64) 9408        base_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2/bn (BatchNormaliza (None, 112, 112, 64) 256         conv1/7x7_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 112, 112, 64) 0           conv1/7x7_s2/bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 55, 55, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce (Conv2D)     (None, 55, 55, 64)   4096        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 55, 55, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 55, 55, 64)   0           conv2_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj (Conv2D)       (None, 55, 55, 256)  16384       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_1x1_proj/bn (BatchNorma (None, 55, 55, 256)  1024        conv2_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 55, 55, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 55, 55, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 55, 55, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 55, 55, 64)   0           conv2_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 55, 55, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 55, 55, 64)   0           conv2_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_3_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 55, 55, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce (Conv2D)     (None, 28, 28, 128)  32768       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 28, 28, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           conv3_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj (Conv2D)       (None, 28, 28, 512)  131072      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_1x1_proj/bn (BatchNorma (None, 28, 28, 512)  2048        conv3_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           conv3_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           conv3_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_4_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_4_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           conv3_4_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_4_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce (Conv2D)     (None, 14, 14, 256)  131072      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n",
      "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "non_local_block_multi_head (Non (None, 7, 7, 1024)   9703424     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 7, 7, 1024)   4096        non_local_block_multi_head[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1024)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         1049600     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          131200      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            516         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 34,449,988\n",
      "Trainable params: 34,392,772\n",
      "Non-trainable params: 57,216\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a73d251-1037-43f0-8a85-23aeb19327d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, f1_score, accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from preprocessing.class_weights import get_class_weights_Effective_Number_of_Samples\n",
    "from tensorflow_utils.Layers import Non_local_block_multi_head\n",
    "from tensorflow_utils.keras_datagenerators.ImageDataLoader import ImageDataLoader\n",
    "from tensorflow_utils.keras_datagenerators.ImageDataLoader_multilabel import ImageDataLoader_multilabel\n",
    "from tensorflow_utils.keras_datagenerators.ImageDataPreprocessor import ImageDataPreprocessor\n",
    "from preprocessing.data_normalizing_utils import VGGFace2_normalization\n",
    "from tensorflow_utils.Losses import weighted_categorical_crossentropy, categorical_focal_loss\n",
    "from tensorflow_utils.callbacks import best_weights_setter_callback, get_annealing_LRreduce_callback, validation_with_generator_callback_multilabel\n",
    "from tensorflow_utils.models.CNN_models import get_modified_VGGFace2_resnet_model, _get_pretrained_VGGFace2_model\n",
    "from engagementRecognition_DAiSEE import load_labels_to_dict, form_dataframe_of_relative_paths_to_data_with_multilabels\n",
    "# params\n",
    "path_to_test_frames = r'C:\\Users\\Denis\\Desktop\\test_preprocessed\\extracted_faces'\n",
    "path_to_test_labels = r'E:\\Databases\\DAiSEE\\DAiSEE\\Labels\\TestLabels.csv'\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 4\n",
    "batch_size = 64\n",
    "epochs = 30\n",
    "highest_lr = 0.0005\n",
    "lowest_lr = 0.00001\n",
    "momentum = 0.9\n",
    "weighting_beta = 0.99999\n",
    "focal_loss_gamma = 2\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(highest_lr, momentum=momentum, clipnorm=1., decay=1e-6)\n",
    "# load labels\n",
    "dict_labels_test = load_labels_to_dict(path_to_test_labels)\n",
    "# form dataframes with relative paths and labels\n",
    "labels_test = form_dataframe_of_relative_paths_to_data_with_multilabels(path_to_test_frames, dict_labels_test)\n",
    "# add full path to filename\n",
    "\n",
    "labels_test['filename'] = path_to_test_frames + '\\\\' + labels_test['filename']\n",
    "# convert labels into float32 type\n",
    "labels_test['engagement'] = labels_test['engagement'].astype('float32')\n",
    "labels_test['boredom'] = labels_test['boredom'].astype('float32')\n",
    "labels_test['confusion'] = labels_test['confusion'].astype('float32')\n",
    "labels_test['frustration'] = labels_test['frustration'].astype('float32')\n",
    "\n",
    "test_gen = ImageDataLoader_multilabel(paths_with_labels=labels_test, batch_size=batch_size,\n",
    "                                      class_columns=['engagement'],\n",
    "                                      preprocess_function=VGGFace2_normalization,\n",
    "                                      num_classes=num_classes,\n",
    "                                      horizontal_flip=None, vertical_flip=None,\n",
    "                                      shift=None,\n",
    "                                      brightness=None, shearing=None, zooming=None,\n",
    "                                      random_cropping_out=None, rotation=None,\n",
    "                                      scaling=None,\n",
    "                                      channel_random_noise=None, bluring=None,\n",
    "                                      worse_quality=None,\n",
    "                                      mixup=None,\n",
    "                                      pool_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfb4ded1-4356-4ba6-b41e-b3c92c7592cb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.734514713287354 1676 0\n",
      "8.443964958190918 1676 10\n",
      "8.565596342086792 1676 20\n",
      "8.427371978759766 1676 30\n",
      "8.640825510025024 1676 40\n",
      "9.235960960388184 1676 50\n",
      "8.856686115264893 1676 60\n",
      "8.624325037002563 1676 70\n",
      "8.6351900100708 1676 80\n",
      "8.694414615631104 1676 90\n",
      "8.540807485580444 1676 100\n",
      "8.613829612731934 1676 110\n",
      "8.622787952423096 1676 120\n",
      "8.619218111038208 1676 130\n",
      "8.644325494766235 1676 140\n",
      "8.62363862991333 1676 150\n",
      "8.54887080192566 1676 160\n",
      "8.599847793579102 1676 170\n",
      "8.565728425979614 1676 180\n",
      "8.654712438583374 1676 190\n",
      "8.499471426010132 1676 200\n",
      "8.654106616973877 1676 210\n",
      "9.705556631088257 1676 220\n",
      "8.55079197883606 1676 230\n",
      "8.602932929992676 1676 240\n",
      "8.610795259475708 1676 250\n",
      "8.622027397155762 1676 260\n",
      "8.542712450027466 1676 270\n",
      "8.653512477874756 1676 280\n",
      "8.588158369064331 1676 290\n",
      "8.604227304458618 1676 300\n",
      "8.636564254760742 1676 310\n",
      "8.61597490310669 1676 320\n",
      "8.699685096740723 1676 330\n",
      "9.266079902648926 1676 340\n",
      "12.393597602844238 1676 350\n",
      "9.50697660446167 1676 360\n",
      "9.332867860794067 1676 370\n",
      "9.307422637939453 1676 380\n",
      "9.348237752914429 1676 390\n",
      "9.606241703033447 1676 400\n",
      "9.976095914840698 1676 410\n",
      "9.459802389144897 1676 420\n",
      "9.15515685081482 1676 430\n",
      "8.895293951034546 1676 440\n",
      "8.839899063110352 1676 450\n",
      "8.726784944534302 1676 460\n",
      "8.738550424575806 1676 470\n",
      "9.03218388557434 1676 480\n",
      "9.048780918121338 1676 490\n",
      "8.996500492095947 1676 500\n",
      "9.07440185546875 1676 510\n",
      "9.142045259475708 1676 520\n",
      "9.13973617553711 1676 530\n",
      "9.166957378387451 1676 540\n",
      "13.779736995697021 1676 550\n",
      "8.871901750564575 1676 560\n",
      "8.666760206222534 1676 570\n",
      "8.66405463218689 1676 580\n",
      "8.671229124069214 1676 590\n",
      "8.731080770492554 1676 600\n",
      "8.708708763122559 1676 610\n",
      "8.726509809494019 1676 620\n",
      "8.811080932617188 1676 630\n",
      "8.98436188697815 1676 640\n",
      "13.795344591140747 1676 650\n",
      "9.942384958267212 1676 660\n",
      "9.414578676223755 1676 670\n",
      "9.292689323425293 1676 680\n",
      "9.212787628173828 1676 690\n",
      "9.0310537815094 1676 700\n",
      "9.040283203125 1676 710\n",
      "9.266316890716553 1676 720\n",
      "9.384350776672363 1676 730\n",
      "9.132935762405396 1676 740\n",
      "9.193307161331177 1676 750\n",
      "9.169365406036377 1676 760\n",
      "9.431756019592285 1676 770\n",
      "9.084445476531982 1676 780\n",
      "9.42000150680542 1676 790\n",
      "10.007078409194946 1676 800\n",
      "9.556609153747559 1676 810\n",
      "9.329982042312622 1676 820\n",
      "9.259462356567383 1676 830\n",
      "9.256759643554688 1676 840\n",
      "9.822068452835083 1676 850\n",
      "9.603276491165161 1676 860\n",
      "9.284993886947632 1676 870\n",
      "9.205028295516968 1676 880\n",
      "9.338647603988647 1676 890\n",
      "8.977182626724243 1676 900\n",
      "9.07235074043274 1676 910\n",
      "9.353432178497314 1676 920\n",
      "9.498063087463379 1676 930\n",
      "9.346278190612793 1676 940\n",
      "9.229247331619263 1676 950\n",
      "9.004089832305908 1676 960\n",
      "9.035149812698364 1676 970\n",
      "9.049829244613647 1676 980\n",
      "9.042436361312866 1676 990\n",
      "9.069477558135986 1676 1000\n",
      "8.970459938049316 1676 1010\n",
      "9.0405113697052 1676 1020\n",
      "8.98413372039795 1676 1030\n",
      "9.061792135238647 1676 1040\n",
      "9.109487533569336 1676 1050\n",
      "8.948205709457397 1676 1060\n",
      "8.818844318389893 1676 1070\n",
      "8.771283388137817 1676 1080\n",
      "8.942745685577393 1676 1090\n",
      "10.350523233413696 1676 1100\n",
      "10.082300662994385 1676 1110\n",
      "9.425639629364014 1676 1120\n",
      "9.123107433319092 1676 1130\n",
      "9.075658082962036 1676 1140\n",
      "8.925431251525879 1676 1150\n",
      "9.089895009994507 1676 1160\n",
      "9.256673336029053 1676 1170\n",
      "9.297599792480469 1676 1180\n",
      "9.277276754379272 1676 1190\n",
      "9.045125246047974 1676 1200\n",
      "9.25582218170166 1676 1210\n",
      "9.038863182067871 1676 1220\n",
      "9.389142513275146 1676 1230\n",
      "9.407468318939209 1676 1240\n",
      "9.438838481903076 1676 1250\n",
      "8.976484537124634 1676 1260\n",
      "8.977992534637451 1676 1270\n",
      "8.860394716262817 1676 1280\n",
      "8.950003147125244 1676 1290\n",
      "9.390167474746704 1676 1300\n",
      "9.485445737838745 1676 1310\n",
      "9.048363447189331 1676 1320\n",
      "9.182437419891357 1676 1330\n",
      "9.131628274917603 1676 1340\n",
      "9.186986207962036 1676 1350\n",
      "9.006345987319946 1676 1360\n",
      "8.950991868972778 1676 1370\n",
      "8.97049069404602 1676 1380\n",
      "9.08313274383545 1676 1390\n",
      "9.099085569381714 1676 1400\n",
      "9.08511209487915 1676 1410\n",
      "9.048772811889648 1676 1420\n",
      "8.881883382797241 1676 1430\n",
      "9.072125673294067 1676 1440\n",
      "8.838146686553955 1676 1450\n",
      "8.826173305511475 1676 1460\n",
      "9.553914070129395 1676 1470\n",
      "8.904529094696045 1676 1480\n",
      "8.799359321594238 1676 1490\n",
      "9.45413088798523 1676 1500\n",
      "9.844611167907715 1676 1510\n",
      "9.21920108795166 1676 1520\n",
      "8.906372785568237 1676 1530\n",
      "8.788840770721436 1676 1540\n",
      "8.611851692199707 1676 1550\n",
      "8.582590341567993 1676 1560\n",
      "8.575588941574097 1676 1570\n",
      "8.620698690414429 1676 1580\n",
      "9.259451627731323 1676 1590\n",
      "8.838052988052368 1676 1600\n",
      "8.633354902267456 1676 1610\n",
      "8.60209059715271 1676 1620\n",
      "8.576836109161377 1676 1630\n",
      "8.744428157806396 1676 1640\n",
      "8.692461252212524 1676 1650\n",
      "8.568800687789917 1676 1660\n",
      "8.60057258605957 1676 1670\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "predictions=[]\n",
    "real_labels=[]\n",
    "counter=0\n",
    "start=time.time()\n",
    "for x,y in test_gen:\n",
    "    real_labels.append(y)\n",
    "    pred=model.predict(x)\n",
    "    predictions.append(pred)\n",
    "    del x\n",
    "    gc.collect()\n",
    "    if counter%10==0:\n",
    "        print(time.time()-start, test_gen.__len__(), counter)\n",
    "        start=time.time()\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0075300-6725-4923-bfc3-c214bc05d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth=np.concatenate([np.array(item).squeeze() for item in real_labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d59b29be-2be5-47d3-9180-15b60caed832",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=np.concatenate([np.array(item).squeeze() for item in predictions], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac69a820-3c52-471a-be42-18a88d8bf734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3], dtype=int64),\n",
       " array([12767, 50874, 30621, 12968], dtype=int64))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(pred.argmax(axis=-1), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fc8cee8-7ed2-4766-88b1-256fb51f1726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3], dtype=int64),\n",
       " array([  240,  5030, 52982, 48978], dtype=int64))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ground_truth.argmax(axis=-1), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd7b2bce-9e74-4a2e-956f-1e3c5ba05290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   11,   162,     2,    65],\n",
       "       [  712,  2363,  1042,   913],\n",
       "       [ 5694, 26182, 14504,  6602],\n",
       "       [ 6350, 22167, 15073,  5388]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.confusion_matrix(ground_truth.argmax(axis=-1), pred.argmax(axis=-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
